---
layout: post
published: false
title: Reproducibility, Executable Papers, and Knitr
summary: Reproducibility is not a technology problem, but a social problem
---

If I want to write a reproducbile paper the tools are there,
there's [knitr](http://yihui.name/knitr/) for R and [IPython Notebooks](http://ipython.org/notebook.html) for Python,
but the mandate isn't.
The computer science community doesn't require reproducibilty, thereby implicitly approving non-reproducible results.

So sure, everyone says we should have more reproducibility, but what is the price people we're willing to pay for it?
And there is a price to pay.
It'll never be as easy to put out a reproducibile paper as it is to barely scrape together enough work to get a result, slap together a paper, and leave all your code and data to rot on some grad student's laptop.
Then the only thing to do is for every conference to force some kind of reproducibility standard onto every submission?
No.  That would be a diasater.
It's much easier to appear to be sort-of-kind-of reproducible than it is to verify if a paper is in fact reproducible.
The recent [reproducibility measuring paper](http://reproducibility.cs.arizona.edu/) and [subsequent reproduction](http://cs.brown.edu/~sk/Memos/Examining-Reproducibility/) of that paper showed that.

Neither public shaming nor draconian rules will have the desired effect.





